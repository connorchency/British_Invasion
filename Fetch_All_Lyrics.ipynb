{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "bi = pd.read_csv('../British_Invasion/Data/List_of_British_Invasion_artists.csv')\n",
    "print len(bi.artist.values)\n",
    "\n",
    "bi2 = pd.read_csv('../British_Invasion/Data/List_of_Second_British_Invasion_artists.csv')\n",
    "print len(bi2.artist.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def url(artist):\n",
    "    base = \"http://www.lyricsfreak.com/\"\n",
    "    name = artist.lower().strip().translate(None, string.punctuation).split(\" \")\n",
    "    if '' in name:\n",
    "        name.remove('')\n",
    "    init = name[0][0]\n",
    "    search_name = \"+\".join(name)\n",
    "    URL = base + init + \"/\" + search_name + \"/\"\n",
    "    return URL\n",
    "\n",
    "def fetch(artist):\n",
    "    base = \"http://www.lyricsfreak.com\"\n",
    "    song_list = []\n",
    "    URL = url(artist)\n",
    "    page = urllib.urlopen(URL)\n",
    "    soup = bs(page, \"lxml\")\n",
    "    songs = soup.findAll(\"table\", attrs={\"name\": \"song\"})[0].findAll(\"tr\")\n",
    "    for s in songs:\n",
    "        for n in s.findAll(\"td\", attrs={\"class\": \"colfirst\"}):\n",
    "            name = re.sub(\" Lyrics\",\"\",n.find('a').attrs[\"title\"])\n",
    "            lyric_link = base + n.find('a').attrs[\"href\"]\n",
    "            song_list.append({name:lyric_link})\n",
    "    return song_list\n",
    "\n",
    "def fetch_all_artists(artist_list):\n",
    "    lists = {}\n",
    "    for i, artist in enumerate(artist_list):\n",
    "        # print artist\n",
    "        # print \"\\r{}%\".format(100.0*(i+1)/len(artist_list)),\n",
    "        song_list = []\n",
    "        if artist[:3].lower() == 'the':\n",
    "            try:\n",
    "                song_list = fetch(artist)\n",
    "            except IndexError:\n",
    "                pass\n",
    "            try:\n",
    "                song_list += fetch(artist[4:])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        elif 'and' in artist.split(\" \"):\n",
    "            try:\n",
    "                song_list = fetch(artist)\n",
    "            except IndexError:\n",
    "                pass\n",
    "            try:\n",
    "                song_list += fetch(re.sub(' and ', ' & ', artist))\n",
    "            except IndexError:\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                song_list = fetch(artist)\n",
    "            except:\n",
    "                print \"[Warning!] {}: Not Exist\".format(artist)\n",
    "        lists[artist] = song_list\n",
    "    return lists\n",
    "\n",
    "def ly_correct_url(URL):\n",
    "    # input: lyric_page_url\n",
    "    # output: lyric_correct_url\n",
    "    page = urllib.urlopen(URL)\n",
    "    soup = bs(page, 'lxml')\n",
    "    base = 'http://www.lyricsfreak.com'\n",
    "    return base + soup.find_all('a', attrs={'class': 'lb-correct'})[0].attrs['href']\n",
    "\n",
    "def fetch_lyrics(URL):\n",
    "    # input: lyric_page_url\n",
    "    URL2 = ly_correct_url(URL)\n",
    "    page = urllib.urlopen(URL2)\n",
    "    soup = bs(page, 'lxml')\n",
    "    lyric_text = soup.findAll('textarea', attrs={'name': 'lyrics'})[0].text\n",
    "    return lyric_text\n",
    "\n",
    "def fetch_one_artist_all_lyrics(artist):\n",
    "    li =  [artist] #;print li\n",
    "    d = fetch_all_artists(li) #;print d\n",
    "    song_list = d[artist]\n",
    "    lyrics_list = {} # {name: lyrics}\n",
    "    for i, song in enumerate(song_list):\n",
    "        # print '\\r{}%'.format(100.0*(i+1)/len(song_list)),\n",
    "        name = song.keys()[0] #;print name\n",
    "        url = song.values()[0] #;print url\n",
    "        lyrics = fetch_lyrics(url)\n",
    "        lyrics_list[name] = lyrics\n",
    "    return lyrics_list\n",
    "\n",
    "def fetch_all_artists_all_lyrics(artist_list):\n",
    "    artists_songs_lyrics = {} # {artist: {song: lyrics}}\n",
    "    for i, artist in enumerate(artist_list):\n",
    "        songs_lyrics = fetch_one_artist_all_lyrics(artist)\n",
    "        artists_songs_lyrics[artist] = songs_lyrics\n",
    "        print '\\r{}%'.format(100.0*(i+1)/len(artist_list)),\n",
    "    return artists_songs_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test \n",
    "#### 1 - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.0%\n"
     ]
    }
   ],
   "source": [
    "res = fetch_all_artists_all_lyrics(bi.artist.values[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chad & Jeremy 17 \b 17\n",
      "Donovan 197 \b 197\n",
      "The Beatles 202 \b 201\n",
      "Petula Clark 69 \b 69\n",
      "The Spencer Davis Group 12 \b 8\n",
      "Dave Dee, Dozy, Beaky, Mick & Tich 9 \b 9\n",
      "The Dave Clark Five 35 \b 20\n",
      "Cilla Black 14 \b 14\n",
      "Cream 45 \b 45\n"
     ]
    }
   ],
   "source": [
    "for k,v in res.iteritems():\n",
    "    print k, len(v), '\\b',\n",
    "    num = 0\n",
    "    for s, ly in v.iteritems():\n",
    "        if ly != u'': # Not Exist!\n",
    "            num += 1\n",
    "    print num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch All - slow - Not Test yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not test yet\n",
    "# slow .. slow .. slow\n",
    "\n",
    "BI1_lyrics = fetch_all_artists_all_lyrics(bi.artist.values)\n",
    "BI2_lyrics = fetch_all_artists_all_lyrics(bi2.artist.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# l = ['Wayne Fontana and the Mindbenders', 'Billy J. Kramer & The Dakotas', 'Dave Dee, Dozy, Beaky, Mick & Tich']\n",
    "# res = fetch_all_artists_all_lyrics(l)\n",
    "# res['Billy J. Kramer & The Dakotas']['Bad To Me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fail to fetch lyrics directly from Lyrics Page\n",
    "# page = urllib.urlopen('http://www.lyricsfreak.com/w/who/another+tricky+day_20146468.html')\n",
    "# soup = bs(page, 'lxml')\n",
    "# a = soup.find_all('div', attrs={'class': 'content song-content floatfix'})[0]\n",
    "# b = a.find_all('div', attrs={'id': 'content'})[0].get_text()\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# l = ['Wayne Fontana and the Mindbenders', 'Billy J. Kramer & The Dakotas', 'Dave Dee, Dozy, Beaky, Mick & Tich']\n",
    "# d = fetch_all_artists(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#song_list = d['Wayne Fontana and the Mindbenders']\n",
    "#fetch_one_artist_all_lyrics(song_list)\n",
    "#fetch_one_artist_all_lyrics('Wayne Fontana and the Mindbenders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ly = fetch_lyrics('http://www.lyricsfreak.com/lyrics_correct.php?song=224460')\n",
    "# ly2 = fetch_lyrics('http://www.lyricsfreak.com/lyrics_correct.php?song=224463')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# page = urllib.urlopen('http://www.lyricsfreak.com/w/who/another+tricky+day_20146468.html')\n",
    "# soup = bs(page, 'lxml')\n",
    "# base = 'http://www.lyricsfreak.com'\n",
    "# page2 = base + soup.find_all('a', attrs={'class': 'lb-correct'})[0].attrs['href']\n",
    "# fetch_lyrics(page2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fetch_lyrics('http://www.lyricsfreak.com/w/who/another+tricky+day_20146468.html')\n",
    "# fetch_lyrics('http://www.lyricsfreak.com/w/who/905_20146806.html')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
