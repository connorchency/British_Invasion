{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bi = pd.read_csv('../Data/List_of_British_Invasion_artists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bi_list = list(bi.artist.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charts = pd.read_csv('../Data/1964_1969_Billboard_Charts.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chart_list = list(charts.artist.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artists_to_fetch = []\n",
    "for item in chart_list:\n",
    "    if item in bi_list:\n",
    "        pass\n",
    "    else:\n",
    "        artists_to_fetch.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1305"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chart_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(artists_to_fetch)\n",
    "charts = charts[charts.artist.isin(artists_to_fetch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandasql as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = '''\n",
    "    select artist, count(song) as total_top_100 from\n",
    "    (select distinct artist, song from charts)\n",
    "    group by artist \n",
    "    order by count(song) asc\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Artists_total_100 = ps.sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artists_to_fetch = Artists_total_100[\"artist\"][Artists_total_100[\"total_top_100\"] > 10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artists_to_fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def url(artist):\n",
    "    base = \"http://www.lyricsfreak.com/\"\n",
    "    name = artist.lower().strip().translate(None, string.punctuation).split(\" \")\n",
    "    if '' in name:\n",
    "        name.remove('')\n",
    "    init = name[0][0]\n",
    "    search_name = \"+\".join(name)\n",
    "    URL = base + init + \"/\" + search_name + \"/\"\n",
    "    return URL\n",
    "\n",
    "def fetch(artist):\n",
    "    base = \"http://www.lyricsfreak.com\"\n",
    "    song_list = []\n",
    "    URL = url(artist)\n",
    "    page = urllib.urlopen(URL)\n",
    "    soup = bs(page, \"lxml\")\n",
    "    songs = soup.findAll(\"table\", attrs={\"name\": \"song\"})[0].findAll(\"tr\")\n",
    "    for s in songs:\n",
    "        for n in s.findAll(\"td\", attrs={\"class\": \"colfirst\"}):\n",
    "            name = re.sub(\" Lyrics\",\"\",n.find('a').attrs[\"title\"])\n",
    "            lyric_link = base + n.find('a').attrs[\"href\"]\n",
    "            song_list.append({name:lyric_link})\n",
    "    return song_list\n",
    "\n",
    "def fetch_all_artists(artist_list):\n",
    "    lists = {}\n",
    "    for i, artist in enumerate(artist_list):\n",
    "        # print artist\n",
    "        # print \"\\r{}%\".format(100.0*(i+1)/len(artist_list)),\n",
    "        song_list = []\n",
    "        if artist[:3].lower() == 'the':\n",
    "            try:\n",
    "                song_list = fetch(artist)\n",
    "            except IndexError:\n",
    "                pass\n",
    "            try:\n",
    "                song_list += fetch(artist[4:])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        elif 'and' in artist.split(\" \"):\n",
    "            try:\n",
    "                song_list = fetch(artist)\n",
    "            except IndexError:\n",
    "                pass\n",
    "            try:\n",
    "                song_list += fetch(re.sub(' and ', ' & ', artist))\n",
    "            except IndexError:\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                song_list = fetch(artist)\n",
    "            except:\n",
    "                print \"[Warning!] {}: Not Exist\".format(artist)\n",
    "        lists[artist] = song_list\n",
    "    return lists\n",
    "\n",
    "def ly_correct_url(URL):\n",
    "    # input: lyric_page_url\n",
    "    # output: lyric_correct_url\n",
    "    page = urllib.urlopen(URL)\n",
    "    soup = bs(page, 'lxml')\n",
    "    base = 'http://www.lyricsfreak.com'\n",
    "    try:\n",
    "        correct_url = base + soup.find_all('a', attrs={'class': 'lb-correct'})[0].attrs['href']\n",
    "    except IndexError:\n",
    "        correct_url = None\n",
    "    return correct_url\n",
    "\n",
    "def fetch_lyrics(URL):\n",
    "    # input: lyric_page_url\n",
    "    URL2 = ly_correct_url(URL)\n",
    "    if URL2:\n",
    "        page = urllib.urlopen(URL2)\n",
    "        soup = bs(page, 'lxml')\n",
    "        lyric_text = soup.findAll('textarea', attrs={'name': 'lyrics'})[0].text\n",
    "        return lyric_text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def fetch_one_artist_all_lyrics(artist):\n",
    "    li =  [artist] #;print li\n",
    "    d = fetch_all_artists(li) #;print d\n",
    "    song_list = d[artist]\n",
    "    lyrics_list = {} # {name: lyrics}\n",
    "    for i, song in enumerate(song_list):\n",
    "        # print '\\r{}%'.format(100.0*(i+1)/len(song_list)),\n",
    "        name = song.keys()[0] #;print name\n",
    "        url = song.values()[0] #;print url\n",
    "        lyrics = fetch_lyrics(url)\n",
    "        lyrics_list[name] = lyrics\n",
    "    return lyrics_list\n",
    "\n",
    "def fetch_all_artists_all_lyrics(artist_list):\n",
    "    artists_songs_lyrics = {} # {artist: {song: lyrics}}\n",
    "    for i, artist in enumerate(artist_list):\n",
    "        songs_lyrics = fetch_one_artist_all_lyrics(artist)\n",
    "        artists_songs_lyrics[artist] = songs_lyrics\n",
    "        print '\\r{}%'.format(100.0*(i+1)/len(artist_list)),\n",
    "    return artists_songs_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = artists_to_fetch\n",
    "a = map(lambda x: str(x), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.7356321839% [Warning!] Trini Lopez: Not Exist\n",
      "34.4827586207%     [Warning!] Paul Revere & The Raiders Featuring Mark Lindsay: Not Exist\n",
      "85.0574712644% [Warning!] James Brown And The Famous Flames: Not Exist\n",
      "95.4022988506% [Warning!] Elvis Presley With The Jordanaires: Not Exist\n",
      "100.0%5747126%   \n"
     ]
    }
   ],
   "source": [
    "res = fetch_all_artists_all_lyrics(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "with open(\"./Billboard_Songs.pkl\", 'wb') as fi:\n",
    "    pickle.dump(res, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./Billboard_Songs.pkl\", 'r') as fi:\n",
    "    ly_bb = pickle.load(fi)\n",
    "\n",
    "def dict2df(ly):\n",
    "    df = pd.DataFrame(columns=['Artist', 'Song', 'Lyrics'])\n",
    "    for a in ly:\n",
    "        artist = a\n",
    "        song_list = ly[a]\n",
    "        if isinstance(song_list, dict):\n",
    "            for s in song_list:\n",
    "                song = s\n",
    "                lyrics = song_list[s]\n",
    "                record = pd.DataFrame.from_dict({'Artist': artist,\n",
    "                                                 'Song': song,\n",
    "                                                 'Lyrics': lyrics}\n",
    "                                                ,orient='index').T\n",
    "                df = df.append(record)  \n",
    "    df = df.loc[:,['Artist', 'Song', 'Lyrics']]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_bb = dict2df(ly_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_bb.to_csv('../Data/Contemporary_Artists_Song_Lyrics.csv', encoding='utf-8', quoting=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
